{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/4d/e260fc004307d6ebc4909ee25e6c918a2399a7fb91975afd95ec48d1c8b4/imbalanced-learn-0.4.3.tar.gz (169kB)\n",
      "Requirement already satisfied: numpy>=1.8.2 in c:\\users\\admin\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\admin\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\admin\\anaconda\\lib\\site-packages (from imbalanced-learn->imblearn) (0.20.1)\n",
      "Building wheels for collected packages: imbalanced-learn\n",
      "  Running setup.py bdist_wheel for imbalanced-learn: started\n",
      "  Running setup.py bdist_wheel for imbalanced-learn: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Admin\\AppData\\Local\\pip\\Cache\\wheels\\94\\6c\\0c\\d7254937a767ff72814aa542997d0e889bed37c1d31ba3de1a\n",
      "Successfully built imbalanced-learn\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.4.3 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import statsmodels.api as smf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.linear_model as sklm \n",
    "import sklearn.decomposition as skdc\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.pipeline as skpl \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"exoTrain.csv\")\n",
    "test = pd.read_csv(\"exoTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
       "0      2    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1      2   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2      2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3      2   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4      2 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "\n",
       "    FLUX.8  FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0   -96.27  -79.89    ...         -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97    ...          -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56    ...         -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42    ...           5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57    ...        -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5087.000000</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5.087000e+03</td>\n",
       "      <td>5087.000000</td>\n",
       "      <td>5087.000000</td>\n",
       "      <td>5087.000000</td>\n",
       "      <td>5087.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.007273</td>\n",
       "      <td>1.445054e+02</td>\n",
       "      <td>1.285778e+02</td>\n",
       "      <td>1.471348e+02</td>\n",
       "      <td>1.561512e+02</td>\n",
       "      <td>1.561477e+02</td>\n",
       "      <td>1.469646e+02</td>\n",
       "      <td>1.168380e+02</td>\n",
       "      <td>1.144983e+02</td>\n",
       "      <td>1.228639e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>3.485578e+02</td>\n",
       "      <td>4.956476e+02</td>\n",
       "      <td>6.711211e+02</td>\n",
       "      <td>7.468790e+02</td>\n",
       "      <td>6.937372e+02</td>\n",
       "      <td>6.553031e+02</td>\n",
       "      <td>-494.784966</td>\n",
       "      <td>-544.594264</td>\n",
       "      <td>-440.239100</td>\n",
       "      <td>-300.536399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.084982</td>\n",
       "      <td>2.150669e+04</td>\n",
       "      <td>2.179717e+04</td>\n",
       "      <td>2.191309e+04</td>\n",
       "      <td>2.223366e+04</td>\n",
       "      <td>2.308448e+04</td>\n",
       "      <td>2.410567e+04</td>\n",
       "      <td>2.414109e+04</td>\n",
       "      <td>2.290691e+04</td>\n",
       "      <td>2.102681e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.864786e+04</td>\n",
       "      <td>3.551876e+04</td>\n",
       "      <td>4.349963e+04</td>\n",
       "      <td>4.981375e+04</td>\n",
       "      <td>5.087103e+04</td>\n",
       "      <td>5.339979e+04</td>\n",
       "      <td>17844.469520</td>\n",
       "      <td>17722.339334</td>\n",
       "      <td>16273.406292</td>\n",
       "      <td>14459.795577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.278563e+05</td>\n",
       "      <td>-3.154408e+05</td>\n",
       "      <td>-2.840018e+05</td>\n",
       "      <td>-2.340069e+05</td>\n",
       "      <td>-4.231956e+05</td>\n",
       "      <td>-5.975521e+05</td>\n",
       "      <td>-6.724046e+05</td>\n",
       "      <td>-5.790136e+05</td>\n",
       "      <td>-3.973882e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.240480e+05</td>\n",
       "      <td>-3.045540e+05</td>\n",
       "      <td>-2.933140e+05</td>\n",
       "      <td>-2.838420e+05</td>\n",
       "      <td>-3.288214e+05</td>\n",
       "      <td>-5.028894e+05</td>\n",
       "      <td>-775322.000000</td>\n",
       "      <td>-732006.000000</td>\n",
       "      <td>-700992.000000</td>\n",
       "      <td>-643170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-4.234000e+01</td>\n",
       "      <td>-3.952000e+01</td>\n",
       "      <td>-3.850500e+01</td>\n",
       "      <td>-3.505000e+01</td>\n",
       "      <td>-3.195500e+01</td>\n",
       "      <td>-3.338000e+01</td>\n",
       "      <td>-2.813000e+01</td>\n",
       "      <td>-2.784000e+01</td>\n",
       "      <td>-2.683500e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.760000e+01</td>\n",
       "      <td>-1.948500e+01</td>\n",
       "      <td>-1.757000e+01</td>\n",
       "      <td>-2.076000e+01</td>\n",
       "      <td>-2.226000e+01</td>\n",
       "      <td>-2.440500e+01</td>\n",
       "      <td>-26.760000</td>\n",
       "      <td>-24.065000</td>\n",
       "      <td>-21.135000</td>\n",
       "      <td>-19.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-7.100000e-01</td>\n",
       "      <td>-8.900000e-01</td>\n",
       "      <td>-7.400000e-01</td>\n",
       "      <td>-4.000000e-01</td>\n",
       "      <td>-6.100000e-01</td>\n",
       "      <td>-1.030000e+00</td>\n",
       "      <td>-8.700000e-01</td>\n",
       "      <td>-6.600000e-01</td>\n",
       "      <td>-5.600000e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.600000e+00</td>\n",
       "      <td>2.680000e+00</td>\n",
       "      <td>3.050000e+00</td>\n",
       "      <td>3.590000e+00</td>\n",
       "      <td>3.230000e+00</td>\n",
       "      <td>3.500000e+00</td>\n",
       "      <td>-0.680000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.825500e+01</td>\n",
       "      <td>4.428500e+01</td>\n",
       "      <td>4.232500e+01</td>\n",
       "      <td>3.976500e+01</td>\n",
       "      <td>3.975000e+01</td>\n",
       "      <td>3.514000e+01</td>\n",
       "      <td>3.406000e+01</td>\n",
       "      <td>3.170000e+01</td>\n",
       "      <td>3.045500e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.211000e+01</td>\n",
       "      <td>2.235000e+01</td>\n",
       "      <td>2.639500e+01</td>\n",
       "      <td>2.909000e+01</td>\n",
       "      <td>2.780000e+01</td>\n",
       "      <td>3.085500e+01</td>\n",
       "      <td>18.175000</td>\n",
       "      <td>18.770000</td>\n",
       "      <td>19.465000</td>\n",
       "      <td>20.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.439240e+06</td>\n",
       "      <td>1.453319e+06</td>\n",
       "      <td>1.468429e+06</td>\n",
       "      <td>1.495750e+06</td>\n",
       "      <td>1.510937e+06</td>\n",
       "      <td>1.508152e+06</td>\n",
       "      <td>1.465743e+06</td>\n",
       "      <td>1.416827e+06</td>\n",
       "      <td>1.342888e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.779338e+06</td>\n",
       "      <td>2.379227e+06</td>\n",
       "      <td>2.992070e+06</td>\n",
       "      <td>3.434973e+06</td>\n",
       "      <td>3.481220e+06</td>\n",
       "      <td>3.616292e+06</td>\n",
       "      <td>288607.500000</td>\n",
       "      <td>215972.000000</td>\n",
       "      <td>207590.000000</td>\n",
       "      <td>211302.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             LABEL        FLUX.1        FLUX.2        FLUX.3        FLUX.4  \\\n",
       "count  5087.000000  5.087000e+03  5.087000e+03  5.087000e+03  5.087000e+03   \n",
       "mean      1.007273  1.445054e+02  1.285778e+02  1.471348e+02  1.561512e+02   \n",
       "std       0.084982  2.150669e+04  2.179717e+04  2.191309e+04  2.223366e+04   \n",
       "min       1.000000 -2.278563e+05 -3.154408e+05 -2.840018e+05 -2.340069e+05   \n",
       "25%       1.000000 -4.234000e+01 -3.952000e+01 -3.850500e+01 -3.505000e+01   \n",
       "50%       1.000000 -7.100000e-01 -8.900000e-01 -7.400000e-01 -4.000000e-01   \n",
       "75%       1.000000  4.825500e+01  4.428500e+01  4.232500e+01  3.976500e+01   \n",
       "max       2.000000  1.439240e+06  1.453319e+06  1.468429e+06  1.495750e+06   \n",
       "\n",
       "             FLUX.5        FLUX.6        FLUX.7        FLUX.8        FLUX.9  \\\n",
       "count  5.087000e+03  5.087000e+03  5.087000e+03  5.087000e+03  5.087000e+03   \n",
       "mean   1.561477e+02  1.469646e+02  1.168380e+02  1.144983e+02  1.228639e+02   \n",
       "std    2.308448e+04  2.410567e+04  2.414109e+04  2.290691e+04  2.102681e+04   \n",
       "min   -4.231956e+05 -5.975521e+05 -6.724046e+05 -5.790136e+05 -3.973882e+05   \n",
       "25%   -3.195500e+01 -3.338000e+01 -2.813000e+01 -2.784000e+01 -2.683500e+01   \n",
       "50%   -6.100000e-01 -1.030000e+00 -8.700000e-01 -6.600000e-01 -5.600000e-01   \n",
       "75%    3.975000e+01  3.514000e+01  3.406000e+01  3.170000e+01  3.045500e+01   \n",
       "max    1.510937e+06  1.508152e+06  1.465743e+06  1.416827e+06  1.342888e+06   \n",
       "\n",
       "           ...           FLUX.3188     FLUX.3189     FLUX.3190     FLUX.3191  \\\n",
       "count      ...        5.087000e+03  5.087000e+03  5.087000e+03  5.087000e+03   \n",
       "mean       ...        3.485578e+02  4.956476e+02  6.711211e+02  7.468790e+02   \n",
       "std        ...        2.864786e+04  3.551876e+04  4.349963e+04  4.981375e+04   \n",
       "min        ...       -3.240480e+05 -3.045540e+05 -2.933140e+05 -2.838420e+05   \n",
       "25%        ...       -1.760000e+01 -1.948500e+01 -1.757000e+01 -2.076000e+01   \n",
       "50%        ...        2.600000e+00  2.680000e+00  3.050000e+00  3.590000e+00   \n",
       "75%        ...        2.211000e+01  2.235000e+01  2.639500e+01  2.909000e+01   \n",
       "max        ...        1.779338e+06  2.379227e+06  2.992070e+06  3.434973e+06   \n",
       "\n",
       "          FLUX.3192     FLUX.3193      FLUX.3194      FLUX.3195  \\\n",
       "count  5.087000e+03  5.087000e+03    5087.000000    5087.000000   \n",
       "mean   6.937372e+02  6.553031e+02    -494.784966    -544.594264   \n",
       "std    5.087103e+04  5.339979e+04   17844.469520   17722.339334   \n",
       "min   -3.288214e+05 -5.028894e+05 -775322.000000 -732006.000000   \n",
       "25%   -2.226000e+01 -2.440500e+01     -26.760000     -24.065000   \n",
       "50%    3.230000e+00  3.500000e+00      -0.680000       0.360000   \n",
       "75%    2.780000e+01  3.085500e+01      18.175000      18.770000   \n",
       "max    3.481220e+06  3.616292e+06  288607.500000  215972.000000   \n",
       "\n",
       "           FLUX.3196      FLUX.3197  \n",
       "count    5087.000000    5087.000000  \n",
       "mean     -440.239100    -300.536399  \n",
       "std     16273.406292   14459.795577  \n",
       "min   -700992.000000 -643170.000000  \n",
       "25%       -21.135000     -19.820000  \n",
       "50%         0.900000       1.430000  \n",
       "75%        19.465000      20.280000  \n",
       "max    207590.000000  211302.000000  \n",
       "\n",
       "[8 rows x 3198 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>119.88</td>\n",
       "      <td>100.21</td>\n",
       "      <td>86.46</td>\n",
       "      <td>48.68</td>\n",
       "      <td>46.12</td>\n",
       "      <td>39.39</td>\n",
       "      <td>18.57</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>14.52</td>\n",
       "      <td>19.29</td>\n",
       "      <td>14.44</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>13.33</td>\n",
       "      <td>45.50</td>\n",
       "      <td>31.93</td>\n",
       "      <td>35.78</td>\n",
       "      <td>269.43</td>\n",
       "      <td>57.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5736.59</td>\n",
       "      <td>5699.98</td>\n",
       "      <td>5717.16</td>\n",
       "      <td>5692.73</td>\n",
       "      <td>5663.83</td>\n",
       "      <td>5631.16</td>\n",
       "      <td>5626.39</td>\n",
       "      <td>5569.47</td>\n",
       "      <td>5550.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-581.91</td>\n",
       "      <td>-984.09</td>\n",
       "      <td>-1230.89</td>\n",
       "      <td>-1600.45</td>\n",
       "      <td>-1824.53</td>\n",
       "      <td>-2061.17</td>\n",
       "      <td>-2265.98</td>\n",
       "      <td>-2366.19</td>\n",
       "      <td>-2294.86</td>\n",
       "      <td>-2034.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>844.48</td>\n",
       "      <td>817.49</td>\n",
       "      <td>770.07</td>\n",
       "      <td>675.01</td>\n",
       "      <td>605.52</td>\n",
       "      <td>499.45</td>\n",
       "      <td>440.77</td>\n",
       "      <td>362.95</td>\n",
       "      <td>207.27</td>\n",
       "      <td>...</td>\n",
       "      <td>17.82</td>\n",
       "      <td>-51.66</td>\n",
       "      <td>-48.29</td>\n",
       "      <td>-59.99</td>\n",
       "      <td>-82.10</td>\n",
       "      <td>-174.54</td>\n",
       "      <td>-95.23</td>\n",
       "      <td>-162.68</td>\n",
       "      <td>-36.79</td>\n",
       "      <td>30.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-826.00</td>\n",
       "      <td>-827.31</td>\n",
       "      <td>-846.12</td>\n",
       "      <td>-836.03</td>\n",
       "      <td>-745.50</td>\n",
       "      <td>-784.69</td>\n",
       "      <td>-791.22</td>\n",
       "      <td>-746.50</td>\n",
       "      <td>-709.53</td>\n",
       "      <td>...</td>\n",
       "      <td>122.34</td>\n",
       "      <td>93.03</td>\n",
       "      <td>93.03</td>\n",
       "      <td>68.81</td>\n",
       "      <td>9.81</td>\n",
       "      <td>20.75</td>\n",
       "      <td>20.25</td>\n",
       "      <td>-120.81</td>\n",
       "      <td>-257.56</td>\n",
       "      <td>-215.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-39.57</td>\n",
       "      <td>-15.88</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-16.13</td>\n",
       "      <td>-24.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-45.20</td>\n",
       "      <td>-5.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.87</td>\n",
       "      <td>-61.85</td>\n",
       "      <td>-27.15</td>\n",
       "      <td>-21.18</td>\n",
       "      <td>-33.76</td>\n",
       "      <td>-85.34</td>\n",
       "      <td>-81.46</td>\n",
       "      <td>-61.98</td>\n",
       "      <td>-69.34</td>\n",
       "      <td>-17.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7  \\\n",
       "0      2   119.88   100.21    86.46    48.68    46.12    39.39    18.57   \n",
       "1      2  5736.59  5699.98  5717.16  5692.73  5663.83  5631.16  5626.39   \n",
       "2      2   844.48   817.49   770.07   675.01   605.52   499.45   440.77   \n",
       "3      2  -826.00  -827.31  -846.12  -836.03  -745.50  -784.69  -791.22   \n",
       "4      2   -39.57   -15.88    -9.16    -6.37   -16.13   -24.05    -0.90   \n",
       "\n",
       "    FLUX.8   FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0     6.98     6.63    ...          14.52      19.29      14.44      -1.62   \n",
       "1  5569.47  5550.44    ...        -581.91    -984.09   -1230.89   -1600.45   \n",
       "2   362.95   207.27    ...          17.82     -51.66     -48.29     -59.99   \n",
       "3  -746.50  -709.53    ...         122.34      93.03      93.03      68.81   \n",
       "4   -45.20    -5.04    ...         -37.87     -61.85     -27.15     -21.18   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      13.33      45.50      31.93      35.78     269.43      57.72  \n",
       "1   -1824.53   -2061.17   -2265.98   -2366.19   -2294.86   -2034.72  \n",
       "2     -82.10    -174.54     -95.23    -162.68     -36.79      30.63  \n",
       "3       9.81      20.75      20.25    -120.81    -257.56    -215.41  \n",
       "4     -33.76     -85.34     -81.46     -61.98     -69.34     -17.84  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "      <td>570.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.008772</td>\n",
       "      <td>515.411351</td>\n",
       "      <td>738.046404</td>\n",
       "      <td>532.603246</td>\n",
       "      <td>739.618088</td>\n",
       "      <td>530.949807</td>\n",
       "      <td>729.591491</td>\n",
       "      <td>517.421404</td>\n",
       "      <td>720.723544</td>\n",
       "      <td>481.015211</td>\n",
       "      <td>...</td>\n",
       "      <td>60.027754</td>\n",
       "      <td>307.682825</td>\n",
       "      <td>88.976842</td>\n",
       "      <td>301.299895</td>\n",
       "      <td>105.121684</td>\n",
       "      <td>291.509561</td>\n",
       "      <td>256.656789</td>\n",
       "      <td>121.810035</td>\n",
       "      <td>224.806035</td>\n",
       "      <td>133.954544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.093329</td>\n",
       "      <td>12592.950138</td>\n",
       "      <td>12622.940170</td>\n",
       "      <td>12545.065255</td>\n",
       "      <td>12591.933126</td>\n",
       "      <td>12512.976544</td>\n",
       "      <td>12572.187328</td>\n",
       "      <td>12454.094432</td>\n",
       "      <td>12525.496793</td>\n",
       "      <td>12397.610716</td>\n",
       "      <td>...</td>\n",
       "      <td>9528.594808</td>\n",
       "      <td>9588.586341</td>\n",
       "      <td>9497.373179</td>\n",
       "      <td>9611.024800</td>\n",
       "      <td>9611.076529</td>\n",
       "      <td>9654.581767</td>\n",
       "      <td>9362.719825</td>\n",
       "      <td>9487.642217</td>\n",
       "      <td>9483.948248</td>\n",
       "      <td>9700.731923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-59421.000000</td>\n",
       "      <td>-14663.430000</td>\n",
       "      <td>-56580.000000</td>\n",
       "      <td>-10817.590000</td>\n",
       "      <td>-54545.000000</td>\n",
       "      <td>-7744.500000</td>\n",
       "      <td>-53580.000000</td>\n",
       "      <td>-6373.400000</td>\n",
       "      <td>-53832.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-89126.500000</td>\n",
       "      <td>-89432.070000</td>\n",
       "      <td>-89759.940000</td>\n",
       "      <td>-90182.630000</td>\n",
       "      <td>-90225.760000</td>\n",
       "      <td>-90595.000000</td>\n",
       "      <td>-86719.070000</td>\n",
       "      <td>-86911.500000</td>\n",
       "      <td>-87123.260000</td>\n",
       "      <td>-87476.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-22.230000</td>\n",
       "      <td>-22.912500</td>\n",
       "      <td>-22.985000</td>\n",
       "      <td>-18.662500</td>\n",
       "      <td>-20.980000</td>\n",
       "      <td>-21.245000</td>\n",
       "      <td>-22.675000</td>\n",
       "      <td>-22.200000</td>\n",
       "      <td>-22.685000</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.602500</td>\n",
       "      <td>-12.842500</td>\n",
       "      <td>-15.222500</td>\n",
       "      <td>-14.350000</td>\n",
       "      <td>-17.370000</td>\n",
       "      <td>-18.272500</td>\n",
       "      <td>-24.000000</td>\n",
       "      <td>-27.360000</td>\n",
       "      <td>-36.855000</td>\n",
       "      <td>-29.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.195000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>-1.125000</td>\n",
       "      <td>-0.880000</td>\n",
       "      <td>-1.495000</td>\n",
       "      <td>-2.650000</td>\n",
       "      <td>-4.330000</td>\n",
       "      <td>-3.910000</td>\n",
       "      <td>-3.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.585000</td>\n",
       "      <td>3.795000</td>\n",
       "      <td>4.785000</td>\n",
       "      <td>3.910000</td>\n",
       "      <td>5.575000</td>\n",
       "      <td>7.150000</td>\n",
       "      <td>-4.385000</td>\n",
       "      <td>-4.995000</td>\n",
       "      <td>-5.135000</td>\n",
       "      <td>-3.785000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.317500</td>\n",
       "      <td>89.710000</td>\n",
       "      <td>89.827500</td>\n",
       "      <td>73.257500</td>\n",
       "      <td>66.947500</td>\n",
       "      <td>45.147500</td>\n",
       "      <td>38.850000</td>\n",
       "      <td>37.150000</td>\n",
       "      <td>30.670000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.445000</td>\n",
       "      <td>20.472500</td>\n",
       "      <td>25.582500</td>\n",
       "      <td>28.767500</td>\n",
       "      <td>27.455000</td>\n",
       "      <td>35.810000</td>\n",
       "      <td>17.755000</td>\n",
       "      <td>11.745000</td>\n",
       "      <td>12.265000</td>\n",
       "      <td>13.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>290882.500000</td>\n",
       "      <td>290653.500000</td>\n",
       "      <td>290554.000000</td>\n",
       "      <td>290486.500000</td>\n",
       "      <td>290289.000000</td>\n",
       "      <td>289982.500000</td>\n",
       "      <td>289197.500000</td>\n",
       "      <td>288520.500000</td>\n",
       "      <td>287404.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>198420.000000</td>\n",
       "      <td>197888.500000</td>\n",
       "      <td>199639.000000</td>\n",
       "      <td>202007.000000</td>\n",
       "      <td>203730.500000</td>\n",
       "      <td>205924.000000</td>\n",
       "      <td>203193.000000</td>\n",
       "      <td>205050.000000</td>\n",
       "      <td>206884.500000</td>\n",
       "      <td>211488.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LABEL         FLUX.1         FLUX.2         FLUX.3         FLUX.4  \\\n",
       "count  570.000000     570.000000     570.000000     570.000000     570.000000   \n",
       "mean     1.008772     515.411351     738.046404     532.603246     739.618088   \n",
       "std      0.093329   12592.950138   12622.940170   12545.065255   12591.933126   \n",
       "min      1.000000  -59421.000000  -14663.430000  -56580.000000  -10817.590000   \n",
       "25%      1.000000     -22.230000     -22.912500     -22.985000     -18.662500   \n",
       "50%      1.000000       1.195000       0.410000      -1.125000      -0.880000   \n",
       "75%      1.000000      98.317500      89.710000      89.827500      73.257500   \n",
       "max      2.000000  290882.500000  290653.500000  290554.000000  290486.500000   \n",
       "\n",
       "              FLUX.5         FLUX.6         FLUX.7         FLUX.8  \\\n",
       "count     570.000000     570.000000     570.000000     570.000000   \n",
       "mean      530.949807     729.591491     517.421404     720.723544   \n",
       "std     12512.976544   12572.187328   12454.094432   12525.496793   \n",
       "min    -54545.000000   -7744.500000  -53580.000000   -6373.400000   \n",
       "25%       -20.980000     -21.245000     -22.675000     -22.200000   \n",
       "50%        -1.495000      -2.650000      -4.330000      -3.910000   \n",
       "75%        66.947500      45.147500      38.850000      37.150000   \n",
       "max    290289.000000  289982.500000  289197.500000  288520.500000   \n",
       "\n",
       "              FLUX.9      ...            FLUX.3188      FLUX.3189  \\\n",
       "count     570.000000      ...           570.000000     570.000000   \n",
       "mean      481.015211      ...            60.027754     307.682825   \n",
       "std     12397.610716      ...          9528.594808    9588.586341   \n",
       "min    -53832.000000      ...        -89126.500000  -89432.070000   \n",
       "25%       -22.685000      ...            -9.602500     -12.842500   \n",
       "50%        -3.890000      ...             3.585000       3.795000   \n",
       "75%        30.670000      ...            23.445000      20.472500   \n",
       "max    287404.500000      ...        198420.000000  197888.500000   \n",
       "\n",
       "           FLUX.3190      FLUX.3191      FLUX.3192      FLUX.3193  \\\n",
       "count     570.000000     570.000000     570.000000     570.000000   \n",
       "mean       88.976842     301.299895     105.121684     291.509561   \n",
       "std      9497.373179    9611.024800    9611.076529    9654.581767   \n",
       "min    -89759.940000  -90182.630000  -90225.760000  -90595.000000   \n",
       "25%       -15.222500     -14.350000     -17.370000     -18.272500   \n",
       "50%         4.785000       3.910000       5.575000       7.150000   \n",
       "75%        25.582500      28.767500      27.455000      35.810000   \n",
       "max    199639.000000  202007.000000  203730.500000  205924.000000   \n",
       "\n",
       "           FLUX.3194      FLUX.3195      FLUX.3196      FLUX.3197  \n",
       "count     570.000000     570.000000     570.000000     570.000000  \n",
       "mean      256.656789     121.810035     224.806035     133.954544  \n",
       "std      9362.719825    9487.642217    9483.948248    9700.731923  \n",
       "min    -86719.070000  -86911.500000  -87123.260000  -87476.940000  \n",
       "25%       -24.000000     -27.360000     -36.855000     -29.475000  \n",
       "50%        -4.385000      -4.995000      -5.135000      -3.785000  \n",
       "75%        17.755000      11.745000      12.265000      13.205000  \n",
       "max    203193.000000  205050.000000  206884.500000  211488.500000  \n",
       "\n",
       "[8 rows x 3198 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.isna().sum()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.isnull().sum()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test.isna().sum()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test.isnull().sum()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.LABEL.replace((2, 1), (1, 0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.LABEL.replace((2, 1), (1, 0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
       "0      1    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1      1   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2      1   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3      1   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4      1 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "\n",
       "    FLUX.8  FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0   -96.27  -79.89    ...         -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97    ...          -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56    ...         -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42    ...           5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57    ...        -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>119.88</td>\n",
       "      <td>100.21</td>\n",
       "      <td>86.46</td>\n",
       "      <td>48.68</td>\n",
       "      <td>46.12</td>\n",
       "      <td>39.39</td>\n",
       "      <td>18.57</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>14.52</td>\n",
       "      <td>19.29</td>\n",
       "      <td>14.44</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>13.33</td>\n",
       "      <td>45.50</td>\n",
       "      <td>31.93</td>\n",
       "      <td>35.78</td>\n",
       "      <td>269.43</td>\n",
       "      <td>57.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5736.59</td>\n",
       "      <td>5699.98</td>\n",
       "      <td>5717.16</td>\n",
       "      <td>5692.73</td>\n",
       "      <td>5663.83</td>\n",
       "      <td>5631.16</td>\n",
       "      <td>5626.39</td>\n",
       "      <td>5569.47</td>\n",
       "      <td>5550.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-581.91</td>\n",
       "      <td>-984.09</td>\n",
       "      <td>-1230.89</td>\n",
       "      <td>-1600.45</td>\n",
       "      <td>-1824.53</td>\n",
       "      <td>-2061.17</td>\n",
       "      <td>-2265.98</td>\n",
       "      <td>-2366.19</td>\n",
       "      <td>-2294.86</td>\n",
       "      <td>-2034.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>844.48</td>\n",
       "      <td>817.49</td>\n",
       "      <td>770.07</td>\n",
       "      <td>675.01</td>\n",
       "      <td>605.52</td>\n",
       "      <td>499.45</td>\n",
       "      <td>440.77</td>\n",
       "      <td>362.95</td>\n",
       "      <td>207.27</td>\n",
       "      <td>...</td>\n",
       "      <td>17.82</td>\n",
       "      <td>-51.66</td>\n",
       "      <td>-48.29</td>\n",
       "      <td>-59.99</td>\n",
       "      <td>-82.10</td>\n",
       "      <td>-174.54</td>\n",
       "      <td>-95.23</td>\n",
       "      <td>-162.68</td>\n",
       "      <td>-36.79</td>\n",
       "      <td>30.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-826.00</td>\n",
       "      <td>-827.31</td>\n",
       "      <td>-846.12</td>\n",
       "      <td>-836.03</td>\n",
       "      <td>-745.50</td>\n",
       "      <td>-784.69</td>\n",
       "      <td>-791.22</td>\n",
       "      <td>-746.50</td>\n",
       "      <td>-709.53</td>\n",
       "      <td>...</td>\n",
       "      <td>122.34</td>\n",
       "      <td>93.03</td>\n",
       "      <td>93.03</td>\n",
       "      <td>68.81</td>\n",
       "      <td>9.81</td>\n",
       "      <td>20.75</td>\n",
       "      <td>20.25</td>\n",
       "      <td>-120.81</td>\n",
       "      <td>-257.56</td>\n",
       "      <td>-215.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-39.57</td>\n",
       "      <td>-15.88</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-16.13</td>\n",
       "      <td>-24.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-45.20</td>\n",
       "      <td>-5.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.87</td>\n",
       "      <td>-61.85</td>\n",
       "      <td>-27.15</td>\n",
       "      <td>-21.18</td>\n",
       "      <td>-33.76</td>\n",
       "      <td>-85.34</td>\n",
       "      <td>-81.46</td>\n",
       "      <td>-61.98</td>\n",
       "      <td>-69.34</td>\n",
       "      <td>-17.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7  \\\n",
       "0      1   119.88   100.21    86.46    48.68    46.12    39.39    18.57   \n",
       "1      1  5736.59  5699.98  5717.16  5692.73  5663.83  5631.16  5626.39   \n",
       "2      1   844.48   817.49   770.07   675.01   605.52   499.45   440.77   \n",
       "3      1  -826.00  -827.31  -846.12  -836.03  -745.50  -784.69  -791.22   \n",
       "4      1   -39.57   -15.88    -9.16    -6.37   -16.13   -24.05    -0.90   \n",
       "\n",
       "    FLUX.8   FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0     6.98     6.63    ...          14.52      19.29      14.44      -1.62   \n",
       "1  5569.47  5550.44    ...        -581.91    -984.09   -1230.89   -1600.45   \n",
       "2   362.95   207.27    ...          17.82     -51.66     -48.29     -59.99   \n",
       "3  -746.50  -709.53    ...         122.34      93.03      93.03      68.81   \n",
       "4   -45.20    -5.04    ...         -37.87     -61.85     -27.15     -21.18   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      13.33      45.50      31.93      35.78     269.43      57.72  \n",
       "1   -1824.53   -2061.17   -2265.98   -2366.19   -2294.86   -2034.72  \n",
       "2     -82.10    -174.54     -95.23    -162.68     -36.79      30.63  \n",
       "3       9.81      20.75      20.25    -120.81    -257.56    -215.41  \n",
       "4     -33.76     -85.34     -81.46     -61.98     -69.34     -17.84  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xe13c5f8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAEHdJREFUeJzt3X+MZWV9x/H3BxCpP1lkoLiLXVI3rZj4K1sg2jRWDIJtXWLFQrVu6CZbE9pq0h9iY4IVSTS2ohh/lJSVhViQoBZqSHGzSk1jFYaKyA/JroCyQtnFRRStNmu//eM+C5dlZvY+27lzZ5z3K5ncc77Pc+58J9nw4Tnn3HNTVUiSNKqDJt2AJGlpMTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHU5ZNINjMORRx5Zq1evnnQbkrSk3HzzzQ9V1dT+5v1CBsfq1auZnp6edBuStKQk+c4o8zxVJUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC5jDY4k9yb5ZpJbkky32hFJtiTZ1l5XtHqSXJRke5Jbk7xs6H3Wt/nbkqwfZ8+SpLktxIrjt6vqJVW1tu2fC2ytqjXA1rYPcBqwpv1sBD4Og6ABzgNOBE4AztsbNpKkhTeJT46vA17ZtjcDNwDvaPXLqqqAryY5PMkxbe6WqtoNkGQLcCpwxTibnP7zt47z7bVErb3oE5NuQZq4ca84CvhCkpuTbGy1o6vqAYD2elSrrwTuGzp2R6vNVpckTcC4VxyvqKr7kxwFbEnyrTnmZoZazVF/4sGDYNoI8LznPe9AepUkjWCsK46qur+97gQ+x+AaxYPtFBTtdWebvgM4dujwVcD9c9T3/V0XV9Xaqlo7NbXfhztKkg7Q2IIjydOTPHPvNnAKcBtwLbD3zqj1wDVt+1rgLe3uqpOAR9qprOuBU5KsaBfFT2k1SdIEjPNU1dHA55Ls/T3/VFX/muQm4KokG4DvAme0+dcBrwW2Az8Bzgaoqt1JzgduavPes/dCuSRp4Y0tOKrqbuDFM9S/D5w8Q72Ac2Z5r03ApvnuUZLUz0+OS5K6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6GBySpC4GhySpi8EhSepicEiSuhgckqQuBockqYvBIUnqMvbgSHJwkq8n+XzbPy7J15JsS/LpJIe2+lPb/vY2vnroPd7Z6nclec24e5YkzW4hVhxvA+4c2n8/cGFVrQEeBja0+gbg4ap6PnBhm0eS44EzgRcCpwIfS3LwAvQtSZrBWIMjySrgd4B/bPsBXgVc3aZsBk5v2+vaPm385DZ/HXBlVf2squ4BtgMnjLNvSdLsxr3i+BDw18D/tv3nAD+oqj1tfwewsm2vBO4DaOOPtPmP1Wc4RpK0wMYWHEl+F9hZVTcPl2eYWvsZm+uY4d+3Mcl0kuldu3Z19ytJGs04VxyvAF6X5F7gSganqD4EHJ7kkDZnFXB/294BHAvQxp8N7B6uz3DMY6rq4qpaW1Vrp6am5v+vkSQBYwyOqnpnVa2qqtUMLm5/sareBHwJeEObth64pm1f2/Zp41+sqmr1M9tdV8cBa4Abx9W3JGluh+x/yrx7B3BlkvcCXwcuafVLgMuTbGew0jgToKpuT3IVcAewBzinqn6+8G1LkmCBgqOqbgBuaNt3M8NdUVX1U+CMWY6/ALhgfB1KkkblJ8clSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUZW3AkOSzJjUm+keT2JH/b6scl+VqSbUk+neTQVn9q29/exlcPvdc7W/2uJK8ZV8+SpP0b54rjZ8CrqurFwEuAU5OcBLwfuLCq1gAPAxva/A3Aw1X1fODCNo8kxwNnAi8ETgU+luTgMfYtSZrD2IKjBh5tu09pPwW8Cri61TcDp7ftdW2fNn5ykrT6lVX1s6q6B9gOnDCuviVJcxvrNY4kBye5BdgJbAG+Dfygqva0KTuAlW17JXAfQBt/BHjOcH2GYyRJC2yswVFVP6+qlwCrGKwSXjDTtPaaWcZmqz9Bko1JppNM79q160BbliTtx4LcVVVVPwBuAE4CDk9ySBtaBdzftncAxwK08WcDu4frMxwz/Dsurqq1VbV2ampqHH+GJIkRgyPJ1lFq+4xPJTm8bf8S8GrgTuBLwBvatPXANW372rZPG/9iVVWrn9nuujoOWAPcOErfkqT5d8hcg0kOA54GHJlkBY+fNnoW8Nz9vPcxwOZ2B9RBwFVV9fkkdwBXJnkv8HXgkjb/EuDyJNsZrDTOBKiq25NcBdwB7AHOqaqfd/6dkqR5MmdwAH8CvJ1BSNzM48HxQ+Cjcx1YVbcCL52hfjcz3BVVVT8FzpjlvS4ALthPr5KkBTBncFTVh4EPJ/mzqvrIAvUkSVrE9rfiAKCqPpLk5cDq4WOq6rIx9SVJWqRGCo4klwO/CtwC7L2+UIDBIUnLzEjBAawFjm93OUmSlrFRP8dxG/DL42xEkrQ0jLriOBK4I8mNDB5eCEBVvW4sXUmSFq1Rg+Pd42xCkrR0jHpX1b+NuxFJ0tIw6l1VP+LxBwseyuAR6T+uqmeNqzFJ0uI06orjmcP7SU7H78SQpGXpgJ6OW1X/zOALmSRJy8yop6peP7R7EIPPdfiZDklahka9q+r3hrb3APcy+EpXSdIyM+o1jrPH3YgkaWkY9YucViX5XJKdSR5M8pkkq8bdnCRp8Rn14vgnGXwT33OBlcC/tJokaZkZNTimquqTVbWn/VwK+MXekrQMjRocDyV5c5KD28+bge+PszFJ0uI0anD8MfBG4L+AB4A3AF4wl6RlaNTbcc8H1lfVwwBJjgD+jkGgSJKWkVFXHC/aGxoAVbUbeOl4WpIkLWajBsdBSVbs3WkrjlFXK5KkXyCj/sf/74GvJLmawaNG3ghcMLauJEmL1qifHL8syTSDBxsGeH1V3THWziRJi9LIp5taUBgWkrTMHdBj1SVJy5fBIUnqYnBIkroYHJKkLgaHJKmLwSFJ6mJwSJK6jC04khyb5EtJ7kxye5K3tfoRSbYk2dZeV7R6klyUZHuSW5O8bOi91rf525KsH1fPkqT9G+eKYw/wF1X1AuAk4JwkxwPnAlurag2wte0DnAasaT8bgY/DY8/FOg84ETgBOG/4uVmSpIU1tuCoqgeq6j/b9o+AOxl87ew6YHObthk4vW2vAy6rga8Chyc5BngNsKWqdrcn9G4BTh1X35KkuS3INY4kqxk8hv1rwNFV9QAMwgU4qk1bCdw3dNiOVputLkmagLEHR5JnAJ8B3l5VP5xr6gy1mqO+7+/ZmGQ6yfSuXbsOrFlJ0n6NNTiSPIVBaHyqqj7byg+2U1C0152tvgM4dujwVcD9c9SfoKourqq1VbV2ampqfv8QSdJjxnlXVYBLgDur6oNDQ9cCe++MWg9cM1R/S7u76iTgkXYq63rglCQr2kXxU1pNkjQB4/wWv1cAfwR8M8ktrfY3wPuAq5JsAL4LnNHGrgNeC2wHfgKcDYOvqU1yPnBTm/ee9tW1kqQJGFtwVNW/M/P1CYCTZ5hfwDmzvNcmYNP8dSdJOlB+clyS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUpexBUeSTUl2JrltqHZEki1JtrXXFa2eJBcl2Z7k1iQvGzpmfZu/Lcn6cfUrSRrNOFcclwKn7lM7F9haVWuArW0f4DRgTfvZCHwcBkEDnAecCJwAnLc3bCRJkzG24KiqLwO79ymvAza37c3A6UP1y2rgq8DhSY4BXgNsqardVfUwsIUnh5EkaQEt9DWOo6vqAYD2elSrrwTuG5q3o9Vmq0uSJmSxXBzPDLWao/7kN0g2JplOMr1r1655bU6S9LiFDo4H2yko2uvOVt8BHDs0bxVw/xz1J6mqi6tqbVWtnZqamvfGJUkDCx0c1wJ774xaD1wzVH9Lu7vqJOCRdirreuCUJCvaRfFTWk2SNCGHjOuNk1wBvBI4MskOBndHvQ+4KskG4LvAGW36dcBrge3AT4CzAapqd5LzgZvavPdU1b4X3CVJC2hswVFVZ80ydPIMcws4Z5b32QRsmsfWJEn/D4vl4rgkaYkwOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktTF4JAkdTE4JEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1MTgkSV0MDklSF4NDktRlyQRHklOT3JVke5JzJ92PJC1XSyI4khwMfBQ4DTgeOCvJ8ZPtSpKWp0Mm3cCITgC2V9XdAEmuBNYBd0y0K2kC3vqV6Um3oEXoEy9fu2C/a0msOICVwH1D+ztaTZK0wJbKiiMz1OoJE5KNwMa2+2iSu8be1fJxJPDQpJtYFD7yD5PuQE/kv81mnv5l/sook5ZKcOwAjh3aXwXcPzyhqi4GLl7IppaLJNNVtXDrYGlE/tucjKVyquomYE2S45IcCpwJXDvhniRpWVoSK46q2pPkT4HrgYOBTVV1+4TbkqRlaUkEB0BVXQdcN+k+lilPAWqx8t/mBKSq9j9LkqRmqVzjkCQtEgaH5uSjXrQYJdmUZGeS2ybdy3JkcGhWPupFi9ilwKmTbmK5Mjg0l8ce9VJV/wPsfdSLNFFV9WVg96T7WK4MDs3FR71IehKDQ3PZ76NeJC0/Bofmst9HvUhafgwOzcVHvUh6EoNDs6qqPcDeR73cCVzlo160GCS5AvgP4NeS7EiyYdI9LSd+clyS1MUVhySpi8EhSepicEiSuhgckqQuBockqYvBIR2AJI/OMfaNdrvocO3SJPckuSXJt5KcNzR2Q3sC8S3t5+pWf3eSvxzfXyEdmCXzDYDSUpDkBQz+h+y3kjy9qn48NPxXVXV1ksOAO5JcVlX3tLE3VdX0gjcsHQBXHNL8+kPgcuALwOtmmXNYe/3xLOPSomZwSPPrD4BPA1cAZ+0z9oEktzB4BtiVVbVzaOxTQ6eqPrBAvUoHxFNV0jxJ8hvArqr6TpIdwKYkK6rq4TZl76mqZwBbk7y8qr7SxjxVpSXDFYc0f84Cfj3JvcC3gWcBv7/vpKp6FLgB+M2FbE6aLwaHNA+SHAScAbyoqlZX1WoG35a47+kqkhwCnMggXKQlx1NV0oF5WjsdtdcHge9V1feGal8Gjk9yTNv/QJJ3AYcCW4HPDs39VJL/btsPVdWr2/a7krx976SqWjWvf4V0AHw6riSpi6eqJEldDA5JUheDQ5LUxeCQJHUxOCRJXQwOSVIXg0OS1MXgkCR1+T+VWCJnIOEC1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='LABEL',data=train, palette='hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x180eff60>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='LABEL',data=test, palette='hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = train.mean(axis=1)\n",
    "train['mean'] = means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = train.iloc[:, 1:3198].std(axis=1)\n",
    "train['std'] = std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = test.iloc[:, 1:3198].std(axis=1)\n",
    "test['std'] = std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
       "0      1    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1      1   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2      1   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3      1   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4      1 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "\n",
       "    FLUX.8  FLUX.9    ...      FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0   -96.27  -79.89    ...         -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97    ...          -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56    ...         -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42    ...           5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57    ...        -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>119.88</td>\n",
       "      <td>100.21</td>\n",
       "      <td>86.46</td>\n",
       "      <td>48.68</td>\n",
       "      <td>46.12</td>\n",
       "      <td>39.39</td>\n",
       "      <td>18.57</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.63</td>\n",
       "      <td>...</td>\n",
       "      <td>19.29</td>\n",
       "      <td>14.44</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>13.33</td>\n",
       "      <td>45.50</td>\n",
       "      <td>31.93</td>\n",
       "      <td>35.78</td>\n",
       "      <td>269.43</td>\n",
       "      <td>57.72</td>\n",
       "      <td>29.816465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5736.59</td>\n",
       "      <td>5699.98</td>\n",
       "      <td>5717.16</td>\n",
       "      <td>5692.73</td>\n",
       "      <td>5663.83</td>\n",
       "      <td>5631.16</td>\n",
       "      <td>5626.39</td>\n",
       "      <td>5569.47</td>\n",
       "      <td>5550.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-984.09</td>\n",
       "      <td>-1230.89</td>\n",
       "      <td>-1600.45</td>\n",
       "      <td>-1824.53</td>\n",
       "      <td>-2061.17</td>\n",
       "      <td>-2265.98</td>\n",
       "      <td>-2366.19</td>\n",
       "      <td>-2294.86</td>\n",
       "      <td>-2034.72</td>\n",
       "      <td>1645.019108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>844.48</td>\n",
       "      <td>817.49</td>\n",
       "      <td>770.07</td>\n",
       "      <td>675.01</td>\n",
       "      <td>605.52</td>\n",
       "      <td>499.45</td>\n",
       "      <td>440.77</td>\n",
       "      <td>362.95</td>\n",
       "      <td>207.27</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.66</td>\n",
       "      <td>-48.29</td>\n",
       "      <td>-59.99</td>\n",
       "      <td>-82.10</td>\n",
       "      <td>-174.54</td>\n",
       "      <td>-95.23</td>\n",
       "      <td>-162.68</td>\n",
       "      <td>-36.79</td>\n",
       "      <td>30.63</td>\n",
       "      <td>117.076869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-826.00</td>\n",
       "      <td>-827.31</td>\n",
       "      <td>-846.12</td>\n",
       "      <td>-836.03</td>\n",
       "      <td>-745.50</td>\n",
       "      <td>-784.69</td>\n",
       "      <td>-791.22</td>\n",
       "      <td>-746.50</td>\n",
       "      <td>-709.53</td>\n",
       "      <td>...</td>\n",
       "      <td>93.03</td>\n",
       "      <td>93.03</td>\n",
       "      <td>68.81</td>\n",
       "      <td>9.81</td>\n",
       "      <td>20.75</td>\n",
       "      <td>20.25</td>\n",
       "      <td>-120.81</td>\n",
       "      <td>-257.56</td>\n",
       "      <td>-215.41</td>\n",
       "      <td>394.506774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-39.57</td>\n",
       "      <td>-15.88</td>\n",
       "      <td>-9.16</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-16.13</td>\n",
       "      <td>-24.05</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-45.20</td>\n",
       "      <td>-5.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.85</td>\n",
       "      <td>-27.15</td>\n",
       "      <td>-21.18</td>\n",
       "      <td>-33.76</td>\n",
       "      <td>-85.34</td>\n",
       "      <td>-81.46</td>\n",
       "      <td>-61.98</td>\n",
       "      <td>-69.34</td>\n",
       "      <td>-17.84</td>\n",
       "      <td>177.043008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7  \\\n",
       "0      1   119.88   100.21    86.46    48.68    46.12    39.39    18.57   \n",
       "1      1  5736.59  5699.98  5717.16  5692.73  5663.83  5631.16  5626.39   \n",
       "2      1   844.48   817.49   770.07   675.01   605.52   499.45   440.77   \n",
       "3      1  -826.00  -827.31  -846.12  -836.03  -745.50  -784.69  -791.22   \n",
       "4      1   -39.57   -15.88    -9.16    -6.37   -16.13   -24.05    -0.90   \n",
       "\n",
       "    FLUX.8   FLUX.9     ...       FLUX.3189  FLUX.3190  FLUX.3191  FLUX.3192  \\\n",
       "0     6.98     6.63     ...           19.29      14.44      -1.62      13.33   \n",
       "1  5569.47  5550.44     ...         -984.09   -1230.89   -1600.45   -1824.53   \n",
       "2   362.95   207.27     ...          -51.66     -48.29     -59.99     -82.10   \n",
       "3  -746.50  -709.53     ...           93.03      93.03      68.81       9.81   \n",
       "4   -45.20    -5.04     ...          -61.85     -27.15     -21.18     -33.76   \n",
       "\n",
       "   FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197          std  \n",
       "0      45.50      31.93      35.78     269.43      57.72    29.816465  \n",
       "1   -2061.17   -2265.98   -2366.19   -2294.86   -2034.72  1645.019108  \n",
       "2    -174.54     -95.23    -162.68     -36.79      30.63   117.076869  \n",
       "3      20.75      20.25    -120.81    -257.56    -215.41   394.506774  \n",
       "4     -85.34     -81.46     -61.98     -69.34     -17.84   177.043008  \n",
       "\n",
       "[5 rows x 3199 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xbb71b38>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"mean\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5087, 3197)\n",
      "(5087L,)\n"
     ]
    }
   ],
   "source": [
    "test.shape\n",
    "#X_train = train.drop('LABEL',axis=1)\n",
    "y_train = train[\"LABEL\"]\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-55f3790076b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m37\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLABEL\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\matplotlib\\__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1865\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1867\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mC:\\Users\\Admin\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.pyc\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[0;32m   4255\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4257\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must be the same size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4259\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x2880 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,40))\n",
    "x = np.array(range(3197))\n",
    "for i in range(37):\n",
    "    ax = fig.add_subplot(13,3,i+1)\n",
    "    ax.scatter(X_train,train[train.LABEL==1].iloc[i,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresion Logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando como predictor la desviación estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 1:50]\n",
    "X_test = test.iloc[:, 1:50]\n",
    "#X_train = train[\"std\"]\n",
    "#X_test = test[\"std\"]\n",
    "y_train = train[\"LABEL\"]\n",
    "y_test = test[\"LABEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5087"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.674387\n",
      "         Iterations 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>  <td>-14.662</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>       <td>LABEL</td>            <td>AIC:</td>        <td>6959.2119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2019-04-23 09:21</td>       <td>BIC:</td>        <td>7279.3996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>5087</td>        <td>Log-Likelihood:</td>   <td>-3430.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>48</td>            <td>LL-Null:</td>       <td>-219.04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>5038</td>         <td>LLR p-value:</td>     <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>        <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>11.0000</td>             <td></td>              <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>      <th>Coef.</th>  <th>Std.Err.</th>    <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.1</th>  <td>-0.0022</td>  <td>0.0004</td>  <td>-5.3361</td> <td>0.0000</td> <td>-0.0031</td> <td>-0.0014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.2</th>  <td>0.0030</td>   <td>0.0005</td>  <td>5.5919</td>  <td>0.0000</td> <td>0.0019</td>  <td>0.0040</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.3</th>  <td>-0.0012</td>  <td>0.0005</td>  <td>-2.2883</td> <td>0.0221</td> <td>-0.0022</td> <td>-0.0002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.4</th>  <td>0.0014</td>   <td>0.0007</td>  <td>2.1444</td>  <td>0.0320</td> <td>0.0001</td>  <td>0.0027</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.5</th>  <td>-0.0013</td>  <td>0.0006</td>  <td>-2.0028</td> <td>0.0452</td> <td>-0.0025</td> <td>-0.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.6</th>  <td>0.0000</td>   <td>0.0006</td>  <td>0.0267</td>  <td>0.9787</td> <td>-0.0011</td> <td>0.0011</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.7</th>  <td>0.0002</td>   <td>0.0006</td>  <td>0.3871</td>  <td>0.6987</td> <td>-0.0010</td> <td>0.0014</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.8</th>  <td>0.0012</td>   <td>0.0006</td>  <td>2.0086</td>  <td>0.0446</td> <td>0.0000</td>  <td>0.0023</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.9</th>  <td>-0.0010</td>  <td>0.0007</td>  <td>-1.3942</td> <td>0.1633</td> <td>-0.0024</td> <td>0.0004</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.10</th> <td>-0.0009</td>  <td>0.0007</td>  <td>-1.2902</td> <td>0.1970</td> <td>-0.0022</td> <td>0.0005</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.11</th> <td>0.0012</td>   <td>0.0006</td>  <td>1.8912</td>  <td>0.0586</td> <td>-0.0000</td> <td>0.0024</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.12</th> <td>-0.0014</td>  <td>0.0006</td>  <td>-2.3845</td> <td>0.0171</td> <td>-0.0026</td> <td>-0.0002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.13</th> <td>-0.0003</td>  <td>0.0007</td>  <td>-0.4608</td> <td>0.6450</td> <td>-0.0017</td> <td>0.0010</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.14</th> <td>0.0036</td>   <td>0.0007</td>  <td>4.9742</td>  <td>0.0000</td> <td>0.0022</td>  <td>0.0050</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.15</th> <td>-0.0034</td>  <td>0.0008</td>  <td>-4.3996</td> <td>0.0000</td> <td>-0.0049</td> <td>-0.0019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.16</th> <td>0.0012</td>   <td>0.0007</td>  <td>1.7922</td>  <td>0.0731</td> <td>-0.0001</td> <td>0.0025</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.17</th> <td>-0.0019</td>  <td>0.0005</td>  <td>-3.4613</td> <td>0.0005</td> <td>-0.0030</td> <td>-0.0008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.18</th> <td>0.0028</td>   <td>0.0007</td>  <td>4.1377</td>  <td>0.0000</td> <td>0.0014</td>  <td>0.0041</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.19</th> <td>0.0001</td>   <td>0.0007</td>  <td>0.1574</td>  <td>0.8749</td> <td>-0.0013</td> <td>0.0015</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.20</th> <td>-0.0010</td>  <td>0.0005</td>  <td>-1.9479</td> <td>0.0514</td> <td>-0.0020</td> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.21</th> <td>-0.0004</td>  <td>0.0003</td>  <td>-1.4628</td> <td>0.1435</td> <td>-0.0011</td> <td>0.0002</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.22</th> <td>0.0003</td>   <td>0.0004</td>  <td>0.5961</td>  <td>0.5511</td> <td>-0.0006</td> <td>0.0011</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.23</th> <td>-0.0001</td>  <td>0.0004</td>  <td>-0.2356</td> <td>0.8138</td> <td>-0.0009</td> <td>0.0007</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.24</th> <td>-0.0000</td>  <td>0.0006</td>  <td>-0.0395</td> <td>0.9685</td> <td>-0.0012</td> <td>0.0011</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.25</th> <td>0.0003</td>   <td>0.0006</td>  <td>0.3957</td>  <td>0.6923</td> <td>-0.0010</td> <td>0.0015</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.26</th> <td>-0.0000</td>  <td>0.0004</td>  <td>-0.1137</td> <td>0.9095</td> <td>-0.0009</td> <td>0.0008</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.27</th> <td>-0.0005</td>  <td>0.0003</td>  <td>-1.5479</td> <td>0.1216</td> <td>-0.0011</td> <td>0.0001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.28</th> <td>0.0014</td>   <td>0.0006</td>  <td>2.3168</td>  <td>0.0205</td> <td>0.0002</td>  <td>0.0026</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.29</th> <td>-0.0004</td>  <td>0.0005</td>  <td>-0.8413</td> <td>0.4002</td> <td>-0.0015</td> <td>0.0006</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.30</th> <td>-0.0009</td>  <td>0.0003</td>  <td>-2.5988</td> <td>0.0094</td> <td>-0.0015</td> <td>-0.0002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.31</th> <td>0.0004</td>   <td>0.0002</td>  <td>2.2992</td>  <td>0.0215</td> <td>0.0001</td>  <td>0.0008</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.32</th> <td>-0.0000</td>  <td>0.0001</td>  <td>-0.2245</td> <td>0.8224</td> <td>-0.0002</td> <td>0.0002</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.33</th> <td>-0.0008</td>  <td>0.0003</td>  <td>-2.7678</td> <td>0.0056</td> <td>-0.0014</td> <td>-0.0002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.34</th> <td>0.0012</td>   <td>0.0006</td>  <td>1.9355</td>  <td>0.0529</td> <td>-0.0000</td> <td>0.0024</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.35</th> <td>-0.0007</td>  <td>0.0006</td>  <td>-1.0969</td> <td>0.2727</td> <td>-0.0019</td> <td>0.0005</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.36</th> <td>-0.0006</td>  <td>0.0006</td>  <td>-1.1147</td> <td>0.2650</td> <td>-0.0018</td> <td>0.0005</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.37</th> <td>0.0026</td>   <td>0.0005</td>  <td>5.0585</td>  <td>0.0000</td> <td>0.0016</td>  <td>0.0036</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.38</th> <td>-0.0016</td>  <td>0.0005</td>  <td>-3.0044</td> <td>0.0027</td> <td>-0.0026</td> <td>-0.0006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.39</th> <td>-0.0008</td>  <td>0.0006</td>  <td>-1.2844</td> <td>0.1990</td> <td>-0.0020</td> <td>0.0004</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.40</th> <td>0.0009</td>   <td>0.0007</td>  <td>1.3343</td>  <td>0.1821</td> <td>-0.0004</td> <td>0.0022</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.41</th> <td>-0.0015</td>  <td>0.0008</td>  <td>-1.9106</td> <td>0.0561</td> <td>-0.0031</td> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.42</th> <td>0.0031</td>   <td>0.0007</td>  <td>4.6190</td>  <td>0.0000</td> <td>0.0018</td>  <td>0.0044</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.43</th> <td>-0.0024</td>  <td>0.0006</td>  <td>-3.8015</td> <td>0.0001</td> <td>-0.0036</td> <td>-0.0011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.44</th> <td>0.0004</td>   <td>0.0005</td>  <td>0.6898</td>  <td>0.4903</td> <td>-0.0007</td> <td>0.0014</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.45</th> <td>-0.0009</td>  <td>0.0004</td>  <td>-2.1815</td> <td>0.0291</td> <td>-0.0017</td> <td>-0.0001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.46</th> <td>0.0021</td>   <td>0.0005</td>  <td>3.8665</td>  <td>0.0001</td> <td>0.0010</td>  <td>0.0032</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.47</th> <td>-0.0006</td>  <td>0.0006</td>  <td>-0.9655</td> <td>0.3343</td> <td>-0.0017</td> <td>0.0006</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.48</th> <td>-0.0007</td>  <td>0.0006</td>  <td>-1.3034</td> <td>0.1924</td> <td>-0.0018</td> <td>0.0004</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FLUX.49</th> <td>0.0003</td>   <td>0.0003</td>  <td>1.1323</td>  <td>0.2575</td> <td>-0.0002</td> <td>0.0008</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: Logit\n",
       "================================================================\n",
       "Model:              Logit            Pseudo R-squared: -14.662  \n",
       "Dependent Variable: LABEL            AIC:              6959.2119\n",
       "Date:               2019-04-23 09:21 BIC:              7279.3996\n",
       "No. Observations:   5087             Log-Likelihood:   -3430.6  \n",
       "Df Model:           48               LL-Null:          -219.04  \n",
       "Df Residuals:       5038             LLR p-value:      1.0000   \n",
       "Converged:          1.0000           Scale:            1.0000   \n",
       "No. Iterations:     11.0000                                     \n",
       "-----------------------------------------------------------------\n",
       "              Coef.   Std.Err.     z     P>|z|    [0.025   0.975]\n",
       "-----------------------------------------------------------------\n",
       "FLUX.1       -0.0022    0.0004  -5.3361  0.0000  -0.0031  -0.0014\n",
       "FLUX.2        0.0030    0.0005   5.5919  0.0000   0.0019   0.0040\n",
       "FLUX.3       -0.0012    0.0005  -2.2883  0.0221  -0.0022  -0.0002\n",
       "FLUX.4        0.0014    0.0007   2.1444  0.0320   0.0001   0.0027\n",
       "FLUX.5       -0.0013    0.0006  -2.0028  0.0452  -0.0025  -0.0000\n",
       "FLUX.6        0.0000    0.0006   0.0267  0.9787  -0.0011   0.0011\n",
       "FLUX.7        0.0002    0.0006   0.3871  0.6987  -0.0010   0.0014\n",
       "FLUX.8        0.0012    0.0006   2.0086  0.0446   0.0000   0.0023\n",
       "FLUX.9       -0.0010    0.0007  -1.3942  0.1633  -0.0024   0.0004\n",
       "FLUX.10      -0.0009    0.0007  -1.2902  0.1970  -0.0022   0.0005\n",
       "FLUX.11       0.0012    0.0006   1.8912  0.0586  -0.0000   0.0024\n",
       "FLUX.12      -0.0014    0.0006  -2.3845  0.0171  -0.0026  -0.0002\n",
       "FLUX.13      -0.0003    0.0007  -0.4608  0.6450  -0.0017   0.0010\n",
       "FLUX.14       0.0036    0.0007   4.9742  0.0000   0.0022   0.0050\n",
       "FLUX.15      -0.0034    0.0008  -4.3996  0.0000  -0.0049  -0.0019\n",
       "FLUX.16       0.0012    0.0007   1.7922  0.0731  -0.0001   0.0025\n",
       "FLUX.17      -0.0019    0.0005  -3.4613  0.0005  -0.0030  -0.0008\n",
       "FLUX.18       0.0028    0.0007   4.1377  0.0000   0.0014   0.0041\n",
       "FLUX.19       0.0001    0.0007   0.1574  0.8749  -0.0013   0.0015\n",
       "FLUX.20      -0.0010    0.0005  -1.9479  0.0514  -0.0020   0.0000\n",
       "FLUX.21      -0.0004    0.0003  -1.4628  0.1435  -0.0011   0.0002\n",
       "FLUX.22       0.0003    0.0004   0.5961  0.5511  -0.0006   0.0011\n",
       "FLUX.23      -0.0001    0.0004  -0.2356  0.8138  -0.0009   0.0007\n",
       "FLUX.24      -0.0000    0.0006  -0.0395  0.9685  -0.0012   0.0011\n",
       "FLUX.25       0.0003    0.0006   0.3957  0.6923  -0.0010   0.0015\n",
       "FLUX.26      -0.0000    0.0004  -0.1137  0.9095  -0.0009   0.0008\n",
       "FLUX.27      -0.0005    0.0003  -1.5479  0.1216  -0.0011   0.0001\n",
       "FLUX.28       0.0014    0.0006   2.3168  0.0205   0.0002   0.0026\n",
       "FLUX.29      -0.0004    0.0005  -0.8413  0.4002  -0.0015   0.0006\n",
       "FLUX.30      -0.0009    0.0003  -2.5988  0.0094  -0.0015  -0.0002\n",
       "FLUX.31       0.0004    0.0002   2.2992  0.0215   0.0001   0.0008\n",
       "FLUX.32      -0.0000    0.0001  -0.2245  0.8224  -0.0002   0.0002\n",
       "FLUX.33      -0.0008    0.0003  -2.7678  0.0056  -0.0014  -0.0002\n",
       "FLUX.34       0.0012    0.0006   1.9355  0.0529  -0.0000   0.0024\n",
       "FLUX.35      -0.0007    0.0006  -1.0969  0.2727  -0.0019   0.0005\n",
       "FLUX.36      -0.0006    0.0006  -1.1147  0.2650  -0.0018   0.0005\n",
       "FLUX.37       0.0026    0.0005   5.0585  0.0000   0.0016   0.0036\n",
       "FLUX.38      -0.0016    0.0005  -3.0044  0.0027  -0.0026  -0.0006\n",
       "FLUX.39      -0.0008    0.0006  -1.2844  0.1990  -0.0020   0.0004\n",
       "FLUX.40       0.0009    0.0007   1.3343  0.1821  -0.0004   0.0022\n",
       "FLUX.41      -0.0015    0.0008  -1.9106  0.0561  -0.0031   0.0000\n",
       "FLUX.42       0.0031    0.0007   4.6190  0.0000   0.0018   0.0044\n",
       "FLUX.43      -0.0024    0.0006  -3.8015  0.0001  -0.0036  -0.0011\n",
       "FLUX.44       0.0004    0.0005   0.6898  0.4903  -0.0007   0.0014\n",
       "FLUX.45      -0.0009    0.0004  -2.1815  0.0291  -0.0017  -0.0001\n",
       "FLUX.46       0.0021    0.0005   3.8665  0.0001   0.0010   0.0032\n",
       "FLUX.47      -0.0006    0.0006  -0.9655  0.3343  -0.0017   0.0006\n",
       "FLUX.48      -0.0007    0.0006  -1.3034  0.1924  -0.0018   0.0004\n",
       "FLUX.49       0.0003    0.0003   1.1323  0.2575  -0.0002   0.0008\n",
       "================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = smf.Logit(y_train, X_train).fit()\n",
    "est.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLUX.1    -0.002240\n",
       "FLUX.2     0.002991\n",
       "FLUX.3    -0.001160\n",
       "FLUX.4     0.001421\n",
       "FLUX.5    -0.001259\n",
       "FLUX.6     0.000015\n",
       "FLUX.7     0.000235\n",
       "FLUX.8     0.001185\n",
       "FLUX.9    -0.001001\n",
       "FLUX.10   -0.000887\n",
       "FLUX.11    0.001196\n",
       "FLUX.12   -0.001403\n",
       "FLUX.13   -0.000322\n",
       "FLUX.14    0.003577\n",
       "FLUX.15   -0.003360\n",
       "FLUX.16    0.001209\n",
       "FLUX.17   -0.001896\n",
       "FLUX.18    0.002753\n",
       "FLUX.19    0.000111\n",
       "FLUX.20   -0.001015\n",
       "FLUX.21   -0.000450\n",
       "FLUX.22    0.000259\n",
       "FLUX.23   -0.000095\n",
       "FLUX.24   -0.000023\n",
       "FLUX.25    0.000254\n",
       "FLUX.26   -0.000047\n",
       "FLUX.27   -0.000507\n",
       "FLUX.28    0.001414\n",
       "FLUX.29   -0.000445\n",
       "FLUX.30   -0.000878\n",
       "FLUX.31    0.000445\n",
       "FLUX.32   -0.000022\n",
       "FLUX.33   -0.000790\n",
       "FLUX.34    0.001168\n",
       "FLUX.35   -0.000680\n",
       "FLUX.36   -0.000650\n",
       "FLUX.37    0.002583\n",
       "FLUX.38   -0.001600\n",
       "FLUX.39   -0.000776\n",
       "FLUX.40    0.000876\n",
       "FLUX.41   -0.001518\n",
       "FLUX.42    0.003089\n",
       "FLUX.43   -0.002367\n",
       "FLUX.44    0.000375\n",
       "FLUX.45   -0.000902\n",
       "FLUX.46    0.002122\n",
       "FLUX.47   -0.000562\n",
       "FLUX.48   -0.000720\n",
       "FLUX.49    0.000296\n",
       "dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = est.params\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('error : 100.00', '%')\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = est.predict(X_test)\n",
    "print(\"error : {:.2f}\".format(100*(1-sum(y_test==y_pred_test)/len(y_test))), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.537442\n",
       "1      0.623716\n",
       "2      0.595455\n",
       "3      0.409483\n",
       "4      0.567845\n",
       "5      0.500171\n",
       "6      0.477183\n",
       "7      0.503364\n",
       "8      0.646890\n",
       "9      0.553025\n",
       "10     0.492398\n",
       "11     0.513876\n",
       "12     0.490576\n",
       "13     0.510223\n",
       "14     0.484395\n",
       "15     0.493574\n",
       "16     0.481673\n",
       "17     0.515580\n",
       "18     0.501251\n",
       "19     0.516362\n",
       "20     0.504035\n",
       "21     0.391590\n",
       "22     0.504342\n",
       "23     0.528388\n",
       "24     0.502170\n",
       "25     0.449875\n",
       "26     0.502233\n",
       "27     0.418082\n",
       "28     0.441150\n",
       "29     0.508081\n",
       "         ...   \n",
       "540    0.506311\n",
       "541    0.489693\n",
       "542    0.492343\n",
       "543    0.490867\n",
       "544    0.420875\n",
       "545    0.524502\n",
       "546    0.490555\n",
       "547    0.508524\n",
       "548    0.507825\n",
       "549    0.539763\n",
       "550    0.427349\n",
       "551    0.511497\n",
       "552    0.491493\n",
       "553    0.525802\n",
       "554    0.500275\n",
       "555    0.512604\n",
       "556    0.531735\n",
       "557    0.496833\n",
       "558    0.507680\n",
       "559    0.503319\n",
       "560    0.498749\n",
       "561    0.491742\n",
       "562    0.478025\n",
       "563    0.501807\n",
       "564    0.471242\n",
       "565    0.415609\n",
       "566    0.485740\n",
       "567    0.491015\n",
       "568    0.470547\n",
       "569    0.333532\n",
       "Length: 570, dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba con los primeros 50 flujos de luz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 1:50]\n",
    "X_test = test.iloc[:, 1:50]\n",
    "#X_train = train[\"std\"]\n",
    "#X_test = test[\"std\"]\n",
    "y_train = train[\"LABEL\"]\n",
    "y_test = test[\"LABEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.64\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[360, 205],\n",
       "       [  2,   3]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.tolist(), y_pred.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance y oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 1:50]\n",
    "X_test = test.iloc[:, 1:50]\n",
    "#X_train = train[\"std\"]\n",
    "#X_test = test[\"std\"]\n",
    "y_train = train[\"LABEL\"]\n",
    "y_test = test[\"LABEL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5050\n",
       "0    5050\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_smote_train, y_smote = sm.fit_resample(X_train, y_train)\n",
    "pd.Series(y_smote).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote_train = pd.DataFrame(X_smote_train)\n",
    "X_smote_train.columns = X_train.columns\n",
    "\n",
    "y_smote = pd.DataFrame(data=y_smote, columns=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_smote_train, y_smote)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>Si</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>261</td>\n",
       "      <td>304</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>264</td>\n",
       "      <td>306</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No   Si  All\n",
       "Actual                 \n",
       "No        261  304  565\n",
       "Si          3    2    5\n",
       "All       264  306  570"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False  True  True  True  True False False False False False False\n",
      " False False False False False False False False False  True False False\n",
      " False]\n",
      "[31 15 25 36 24 33 43 39 29 41 35 22 20  9 17 27 40  7 34 37 38 42 16 23\n",
      "  8 12  1  1  1  1 14 13 21 44  5 45 19 11  4 32 26  3 30  2 18  1 10  6\n",
      " 28]\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "\n",
    "rfe = RFE(logreg, 5, step=1)\n",
    "rfe = rfe.fit(X_smote_train, y_smote.values.ravel())\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_train = X_smote_train.iloc[:, 27:31]\n",
    "y_new_train = y_smote['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solo Feature Selection RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.99\n"
     ]
    }
   ],
   "source": [
    "X_new_train = X_train.iloc[:, 27:31]\n",
    "X_new_test = X_test.iloc[:, 27:31]\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_new_train, y_train)\n",
    "y_pred = logreg.predict(X_new_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_new_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>570</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No  All\n",
       "Actual            \n",
       "No        565  565\n",
       "Si          5    5\n",
       "All       570  570"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con penalizacion\n",
    "\n",
    "##### Usando sag solver y penalizacion l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X_new_train = X_train.iloc[:, 27:31]\n",
    "X_new_test = X_test.iloc[:, 27:31]\n",
    "logreg = LogisticRegression(solver='lg', penalty='l2')\n",
    "logreg.fit(X_new_train, y_train)\n",
    "y_pred = logreg.predict(X_new_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_new_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>Si</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>299</td>\n",
       "      <td>266</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>302</td>\n",
       "      <td>268</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No   Si  All\n",
       "Actual                 \n",
       "No        299  266  565\n",
       "Si          3    2    5\n",
       "All       302  268  570"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Usando saga solver y penalizacion l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X_new_train = X_train.iloc[:, 27:31]\n",
    "X_new_test = X_test.iloc[:, 27:31]\n",
    "logreg = LogisticRegression(solver='saga', penalty='l2')\n",
    "logreg.fit(X_new_train, y_train)\n",
    "y_pred = logreg.predict(X_new_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_new_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>Si</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>302</td>\n",
       "      <td>263</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>305</td>\n",
       "      <td>265</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No   Si  All\n",
       "Actual                 \n",
       "No        302  263  565\n",
       "Si          3    2    5\n",
       "All       305  265  570"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA y Regresion logistica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 1:3198]\n",
    "X_test = test.iloc[:, 1:3198]\n",
    "y_train = train[\"LABEL\"]\n",
    "y_test = test[\"LABEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = skdc.PCA()\n",
    "pc = pca.fit_transform(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       5.435289e-01\n",
      "1       1.576792e-01\n",
      "2       1.089686e-01\n",
      "3       5.310155e-02\n",
      "4       5.135426e-02\n",
      "5       1.852569e-02\n",
      "6       1.427272e-02\n",
      "7       1.338228e-02\n",
      "8       1.044143e-02\n",
      "9       6.862476e-03\n",
      "10      5.948178e-03\n",
      "11      3.863733e-03\n",
      "12      2.586211e-03\n",
      "13      1.616898e-03\n",
      "14      1.100061e-03\n",
      "15      7.288486e-04\n",
      "16      5.951435e-04\n",
      "17      5.245787e-04\n",
      "18      3.498080e-04\n",
      "19      3.371119e-04\n",
      "20      3.133841e-04\n",
      "21      2.905568e-04\n",
      "22      2.637147e-04\n",
      "23      2.524921e-04\n",
      "24      2.424707e-04\n",
      "25      2.295419e-04\n",
      "26      2.254891e-04\n",
      "27      2.197740e-04\n",
      "28      1.987973e-04\n",
      "29      1.869569e-04\n",
      "            ...     \n",
      "3167    5.066718e-12\n",
      "3168    5.025755e-12\n",
      "3169    4.975917e-12\n",
      "3170    4.938607e-12\n",
      "3171    4.907987e-12\n",
      "3172    4.851340e-12\n",
      "3173    4.816115e-12\n",
      "3174    4.795198e-12\n",
      "3175    4.760524e-12\n",
      "3176    4.706295e-12\n",
      "3177    4.650835e-12\n",
      "3178    4.639733e-12\n",
      "3179    4.614899e-12\n",
      "3180    4.531802e-12\n",
      "3181    4.506506e-12\n",
      "3182    4.468242e-12\n",
      "3183    4.414172e-12\n",
      "3184    4.381736e-12\n",
      "3185    4.332638e-12\n",
      "3186    4.293306e-12\n",
      "3187    4.255393e-12\n",
      "3188    4.188360e-12\n",
      "3189    4.168831e-12\n",
      "3190    4.127012e-12\n",
      "3191    4.122985e-12\n",
      "3192    4.086690e-12\n",
      "3193    4.007090e-12\n",
      "3194    3.955442e-12\n",
      "3195    3.885799e-12\n",
      "3196    3.811257e-12\n",
      "Length: 3197, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "var_explained = pca.explained_variance_ratio_ \n",
    "print(pd.Series(var_explained))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "pca = skdc.PCA(n_components = 30) #only include first 10 components\n",
    "pc = pca.fit(X_train, y_train)\n",
    "X_train_pca = pc.transform(X_train)\n",
    "X_test_pca = pc.transform(X_test)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "logisticRegr.fit(X_train_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logisticRegr.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.887719298245614"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>Si</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>504</td>\n",
       "      <td>61</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>507</td>\n",
       "      <td>63</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No  Si  All\n",
       "Actual                \n",
       "No        504  61  565\n",
       "Si          3   2    5\n",
       "All       507  63  570"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_actual, y_predicho, margins=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con penalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05087719298245614"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "pca = skdc.PCA(n_components = 30) #only include first 10 components\n",
    "pc = pca.fit(X_train, y_train)\n",
    "X_train_pca = pc.transform(X_train)\n",
    "X_test_pca = pc.transform(X_test)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'saga', penalty=\"l2\")\n",
    "\n",
    "logisticRegr.fit(X_train_pca, y_train)\n",
    "y_pred = logisticRegr.predict(X_test_pca)\n",
    "logisticRegr.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>Si</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>26</td>\n",
       "      <td>539</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>28</td>\n",
       "      <td>542</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho  No   Si  All\n",
       "Actual                \n",
       "No        26  539  565\n",
       "Si         2    3    5\n",
       "All       28  542  570"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning de componentes principales seleccionados\n",
    "\n",
    "#### Principal components = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9017543859649123"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "pca = skdc.PCA(n_components = 50) #only include first 10 components\n",
    "pc = pca.fit(X_train, y_train)\n",
    "X_train_pca = pc.transform(X_train)\n",
    "X_test_pca = pc.transform(X_test)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "logisticRegr.fit(X_train_pca, y_train)\n",
    "y_pred = logisticRegr.predict(X_test_pca)\n",
    "logisticRegr.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>Si</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>511</td>\n",
       "      <td>54</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>513</td>\n",
       "      <td>57</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No  Si  All\n",
       "Actual                \n",
       "No        511  54  565\n",
       "Si          2   3    5\n",
       "All       513  57  570"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal components = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9140350877192982"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "pca = skdc.PCA(n_components = 100) #only include first 10 components\n",
    "pc = pca.fit(X_train, y_train)\n",
    "X_train_pca = pc.transform(X_train)\n",
    "X_test_pca = pc.transform(X_test)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "logisticRegr.fit(X_train_pca, y_train)\n",
    "y_pred = logisticRegr.predict(X_test_pca)\n",
    "logisticRegr.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>Si</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>519</td>\n",
       "      <td>46</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>522</td>\n",
       "      <td>48</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No  Si  All\n",
       "Actual                \n",
       "No        519  46  565\n",
       "Si          3   2    5\n",
       "All       522  48  570"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal components = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9157894736842105"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "pca = skdc.PCA(n_components = 200) #only include first 10 components\n",
    "pc = pca.fit(X_train, y_train)\n",
    "X_train_pca = pc.transform(X_train)\n",
    "X_test_pca = pc.transform(X_test)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "logisticRegr.fit(X_train_pca, y_train)\n",
    "y_pred = logisticRegr.predict(X_test_pca)\n",
    "logisticRegr.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>Si</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>519</td>\n",
       "      <td>46</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>521</td>\n",
       "      <td>49</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No  Si  All\n",
       "Actual                \n",
       "No        519  46  565\n",
       "Si          2   3    5\n",
       "All       521  49  570"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### con regularizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9228070175438596"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "pca = skdc.PCA(n_components = 200) #only include first 10 components\n",
    "pc = pca.fit(X_train, y_train)\n",
    "X_train_pca = pc.transform(X_train)\n",
    "X_test_pca = pc.transform(X_test)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "logisticRegr.fit(X_train_pca, y_train)\n",
    "y_pred = logisticRegr.predict(X_test_pca)\n",
    "logisticRegr.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>Si</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>523</td>\n",
       "      <td>42</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>525</td>\n",
       "      <td>45</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No  Si  All\n",
       "Actual                \n",
       "No        523  42  565\n",
       "Si          2   3    5\n",
       "All       525  45  570"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saga solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10350877192982456"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "pca = skdc.PCA(n_components = 200) #only include first 10 components\n",
    "pc = pca.fit(X_train, y_train)\n",
    "X_train_pca = pc.transform(X_train)\n",
    "X_test_pca = pc.transform(X_test)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'saga', penalty='l1')\n",
    "\n",
    "logisticRegr.fit(X_train_pca, y_train)\n",
    "y_pred = logisticRegr.predict(X_test_pca)\n",
    "logisticRegr.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>Si</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>56</td>\n",
       "      <td>509</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>58</td>\n",
       "      <td>512</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho  No   Si  All\n",
       "Actual                \n",
       "No        56  509  565\n",
       "Si         2    3    5\n",
       "All       58  512  570"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal components = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9140350877192982"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "pca = skdc.PCA(n_components = 300) #only include first 10 components\n",
    "pc = pca.fit(X_train, y_train)\n",
    "X_train_pca = pc.transform(X_train)\n",
    "X_test_pca = pc.transform(X_test)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs', penalty='l2')\n",
    "\n",
    "logisticRegr.fit(X_train_pca, y_train)\n",
    "y_pred = logisticRegr.predict(X_test_pca)\n",
    "logisticRegr.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>Si</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>518</td>\n",
       "      <td>47</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>520</td>\n",
       "      <td>50</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No  Si  All\n",
       "Actual                \n",
       "No        518  47  565\n",
       "Si          2   3    5\n",
       "All       520  50  570"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### saga solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06140350877192982"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "pca = skdc.PCA(n_components = 300) #only include first 10 components\n",
    "pc = pca.fit(X_train, y_train)\n",
    "X_train_pca = pc.transform(X_train)\n",
    "X_test_pca = pc.transform(X_test)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'saga', penalty='l2')\n",
    "\n",
    "logisticRegr.fit(X_train_pca, y_train)\n",
    "y_pred = logisticRegr.predict(X_test_pca)\n",
    "logisticRegr.score(X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>Si</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>31</td>\n",
       "      <td>534</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>32</td>\n",
       "      <td>538</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho  No   Si  All\n",
       "Actual                \n",
       "No        31  534  565\n",
       "Si         1    4    5\n",
       "All       32  538  570"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 1:3198]\n",
    "X_test = test.iloc[:, 1:3198]\n",
    "y_train = train[\"LABEL\"]\n",
    "y_test = test[\"LABEL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train) \n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9948889325732259"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912280701754386"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>570</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No  All\n",
       "Actual            \n",
       "No        565  565\n",
       "Si          5    5\n",
       "All       570  570"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.5, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train) \n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.5, kernel='linear',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train score:', 0.9948889325732259)\n",
      "('test score:', 0.9912280701754386)\n"
     ]
    }
   ],
   "source": [
    "print('train score:', clf.score(X_train, y_train))\n",
    "print('test score:', clf.score(X_test, y_test))\n",
    "y_pred= clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>570</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No  All\n",
       "Actual            \n",
       "No        565  565\n",
       "Si          5    5\n",
       "All       570  570"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, cache_size=200, class_weight={1: 10}, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.7, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train) \n",
    "SVC(C=2, cache_size=200, class_weight={1: 10}, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.7, kernel='linear',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train score:', 0.9948889325732259)\n",
      "('test score:', 0.9912280701754386)\n"
     ]
    }
   ],
   "source": [
    "print('train score:', clf.score(X_train, y_train))\n",
    "print('test score:', clf.score(X_test, y_test))\n",
    "y_pred= clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicho</th>\n",
       "      <th>No</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>570</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicho   No  All\n",
       "Actual            \n",
       "No        565  565\n",
       "Si          5    5\n",
       "All       570  570"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_actual = pd.Series(y_test, name = \"Actual\")\n",
    "y_predicted = pd.Series(y_pred, name = \"Predicho\")\n",
    "\n",
    "y_actual = y_actual.replace([0,1],[\"No\",\"Si\"])\n",
    "y_predicho = y_predicted.replace([0,1],[\"No\",\"Si\"])\n",
    "pd.crosstab(y_actual, y_predicho, margins=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
